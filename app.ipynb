{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b4d6c64-d363-423f-930e-926b393eae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "genres = pd.read_csv(\"./train.csv\",usecols=[\"Genre\"])[\"Genre\"].astype(\"category\")\n",
    "genre_to_id = {g: i for i, g in enumerate(genres.cat.categories)}\n",
    "id_to_genre = {i: g for g, i in genre_to_id.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc2d52f-331e-4d6b-9ef4-68cfa7121a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Country', 1: 'Electronic', 2: 'Folk', 3: 'Hip-Hop', 4: 'Indie', 5: 'Jazz', 6: 'Metal', 7: 'Pop', 8: 'R&B', 9: 'Rock'}\n"
     ]
    }
   ],
   "source": [
    " print(id_to_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409b9b64-b8db-4b76-b50e-2b0fd54d7388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk 0\n",
      "Saved chunk 10\n",
      "Saved chunk 20\n",
      "Saved chunk 30\n",
      "Saved chunk 40\n",
      "Saved chunk 50\n",
      "Saved chunk 60\n",
      "Saved chunk 70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "CHUNK_SIZE = 4096\n",
    "OUT_DIR = \"emb\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(\n",
    "        \"/home/abigfatpoo/Downloads/train.csv\",\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        usecols=[\"Lyrics\", \"Genre\"]\n",
    "    )):\n",
    "\n",
    "    # Lyrics → embeddings\n",
    "    texts = chunk[\"Lyrics\"].fillna(\"\").tolist()\n",
    "    X = model.encode(\n",
    "        texts,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    # Genre → IDs (using in-memory dict)\n",
    "    y = chunk[\"Genre\"].map(genre_to_id).to_numpy()\n",
    "\n",
    "    # Save\n",
    "    np.save(f\"{OUT_DIR}/X_{i}.npy\", X)\n",
    "    np.save(f\"{OUT_DIR}/y_{i}.npy\", y)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Saved chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6ddb34-8ca1-4bff-aab2-7c1babc83923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellO\n"
     ]
    }
   ],
   "source": [
    "print(\"hellO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb01dcc-9ff4-4a16-829e-1babfd76df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 71\n",
      "['X_69.npy', 'X_7.npy', 'X_70.npy', 'X_8.npy', 'X_9.npy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "Xs = sorted(f for f in os.listdir(\"emb\") if f.startswith(\"X_\"))\n",
    "ys = sorted(f for f in os.listdir(\"emb\") if f.startswith(\"y_\"))\n",
    "\n",
    "print(len(Xs), len(ys))\n",
    "print(Xs[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4080406c-c9de-437d-ba50-7c01dbe25774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 11160892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n = sum(1 for _ in open(\"./train.csv\")) - 1\n",
    "print(\"Total rows:\", n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc3d311-5df0-45cd-be78-159398c342b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres seen in 71 chunks:\n",
      "['Country', 'Electronic', 'Folk', 'Hip-Hop', 'Indie', 'Jazz', 'Metal', 'Pop', 'R&B', 'Rock']\n",
      "Count: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "for f in os.listdir(\"emb\"):\n",
    "    if f.startswith(\"y_\"):\n",
    "        y = np.load(f\"emb/{f}\")\n",
    "        seen_ids.update(set(y.tolist()))\n",
    "\n",
    "seen_genres = {id_to_genre[i] for i in seen_ids}\n",
    "\n",
    "print(\"Genres seen in 71 chunks:\")\n",
    "print(sorted(seen_genres))\n",
    "print(\"Count:\", len(seen_genres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2ba51a-d0e6-435a-b828-24349b3f60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted rounds: 30\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# sanity: load ONE chunk to initialize model\n",
    "X = np.load(\"emb/X_0.npy\")\n",
    "y = np.load(\"emb/y_0.npy\")\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(genre_to_id),\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "booster = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=30\n",
    ")\n",
    "\n",
    "print(\"Boosted rounds:\", booster.num_boosted_rounds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a0df96-40d0-45c4-993f-7b627954d592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fa840f9e4247959363ed9e111933b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.18815374921235034\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load encoder\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load test data\n",
    "test_df = pd.read_csv(\n",
    "    \"./test.csv\",\n",
    "    usecols=[\"Lyrics\", \"Genre\"]\n",
    ")\n",
    "\n",
    "# labels\n",
    "y_true = test_df[\"Genre\"].map(genre_to_id).to_numpy()\n",
    "\n",
    "# lyrics\n",
    "texts = test_df[\"Lyrics\"].fillna(\"\").tolist()\n",
    "texts = [t[:2000] for t in texts]\n",
    "\n",
    "# embed\n",
    "X_test = model.encode(\n",
    "    texts,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# predict\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "probs = booster.predict(dtest)\n",
    "y_pred = probs.argmax(axis=1)\n",
    "\n",
    "# accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c726aee1-4fea-4aec-961f-7f58d3393ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Boosted rounds: 2130\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(genre_to_id),\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"nthread\": -1\n",
    "}\n",
    "\n",
    "booster = None\n",
    "\n",
    "Xs = sorted(f for f in os.listdir(\"emb\") if f.startswith(\"X_\"))\n",
    "\n",
    "for f in Xs:\n",
    "    idx = f.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    X = np.load(f\"emb/X_{idx}.npy\")\n",
    "    y = np.load(f\"emb/y_{idx}.npy\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=30,\n",
    "        xgb_model=booster\n",
    "    )\n",
    "\n",
    "print(\"Training finished\")\n",
    "print(\"Boosted rounds:\", booster.num_boosted_rounds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1370bac1-d482-42ad-83bf-1e73ef858faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d34254af54493d99d70aa6a0857826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2591052299936988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load encoder\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load test data\n",
    "test_df = pd.read_csv(\n",
    "    \"./test.csv\",\n",
    "    usecols=[\"Lyrics\", \"Genre\"]\n",
    ")\n",
    "\n",
    "# labels\n",
    "y_true = test_df[\"Genre\"].map(genre_to_id).to_numpy()\n",
    "\n",
    "# lyrics\n",
    "texts = test_df[\"Lyrics\"].fillna(\"\").tolist()\n",
    "texts = [t[:2000] for t in texts]\n",
    "\n",
    "# embed\n",
    "X_test = model.encode(\n",
    "    texts,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# predict\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "probs = booster.predict(dtest)\n",
    "y_pred = probs.argmax(axis=1)\n",
    "\n",
    "# accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8b23378-ea43-43ef-8fff-e1731bd0cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train genres: ['Country', 'Electronic', 'Folk', 'Hip-Hop', 'Indie', 'Jazz', 'Metal', 'Pop', 'R&B', 'Rock']\n",
      "Test genres: ['Country', 'Electronic', 'Folk', 'Hip-Hop', 'Indie', 'Jazz', 'Metal', 'Pop', 'R&B', 'Rock']\n",
      "\n",
      "In test but not in train: set()\n",
      "In train but not in test: set()\n"
     ]
    }
   ],
   "source": [
    "# genres in training\n",
    "train_genres = set(genre_to_id.keys())\n",
    "\n",
    "# genres in test\n",
    "test_genres = set(test_df[\"Genre\"].dropna().unique())\n",
    "\n",
    "print(\"Train genres:\", sorted(train_genres))\n",
    "print(\"Test genres:\", sorted(test_genres))\n",
    "\n",
    "print(\"\\nIn test but not in train:\", test_genres - train_genres)\n",
    "print(\"In train but not in test:\", train_genres - test_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27b35f2a-888a-4ae4-82ad-3f901fffdd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE: Hip-Hop\n",
      "PRED: Pop\n",
      "Most folks spend their days daydreaming of finding clues\n",
      "My whole life I've been here at the train station shining shoes\n",
      "I started when I was nine, on my own and taught myself\n",
      "No complaints, I'm doing\n",
      "----------------------------------------\n",
      "TRUE: Indie\n",
      "PRED: Rock\n",
      "Take your cold hands and put them on my face\n",
      "Sharpen your axe and your criminal ways\n",
      "Let's go to town\n",
      "and do what we did before\n",
      "It's gonna hurt\n",
      "but we don't feel pain no more\n",
      "If you're alive can you s\n",
      "----------------------------------------\n",
      "TRUE: Metal\n",
      "PRED: Pop\n",
      "Are you ready it's time for war\n",
      "We'll break down these fucking doors\n",
      "Smash the windows, tear down the walls\n",
      "We won't stop 'til it's all destroyed\n",
      "Let it out, just let it show\n",
      "We'll burn it down, and w\n",
      "----------------------------------------\n",
      "TRUE: Pop\n",
      "PRED: Pop\n",
      "You ask me why I change the color of my hair\n",
      "(Yeah)\n",
      "You ask me why I need thirty two pairs of shoes\n",
      "(To wear)\n",
      "You seem to ask me why I got a lot of things\n",
      "It's just a chick thing, you ought to let it \n",
      "----------------------------------------\n",
      "TRUE: Hip-Hop\n",
      "PRED: Rock\n",
      "Do you believe in magic in a young girl's heart\n",
      "How the music can free her whenever it starts\n",
      "And it's magic, if the music is groovy\n",
      "It makes you feel lovely like an old time movie\n",
      "I'll tell you about\n",
      "----------------------------------------\n",
      "TRUE: Country\n",
      "PRED: Rock\n",
      "People starin' at me as they wheel me down the ramp toward my plane\n",
      "The war is over for me I've forgotten everything except the pain\n",
      "Thank you sir and yes sir it was worth it for the old red-white-and\n",
      "----------------------------------------\n",
      "TRUE: Country\n",
      "PRED: Rock\n",
      "Now as I sigh the hours away\n",
      "I think of love of yesterday\n",
      "Now I know she's gone away\n",
      "She's in heaven so they say\n",
      "Will the angels tell her for me\n",
      "That my love will never die\n",
      "Someday I'll walk along bes\n",
      "----------------------------------------\n",
      "TRUE: Hip-Hop\n",
      "PRED: Metal\n",
      "Tell Mel Shawn to come in\n",
      "Word, yo, one life to live\n",
      "It's on your head\n",
      "Just like my daughters\n",
      "That's my word\n",
      "Polka dot\n",
      "Connection\n",
      "Shine just apostle\n",
      "Yo, my whole body like a spoiler kid, draped in the\n",
      "----------------------------------------\n",
      "TRUE: Indie\n",
      "PRED: Pop\n",
      "All the things we lost in the fire\n",
      "All the things we lost in the flood\n",
      "Broke, Down, Old, Exposed\n",
      "Those things only took, they never gave any love\n",
      "Sleepy headed, so lost in your compass\n",
      "So much so that\n",
      "----------------------------------------\n",
      "TRUE: Pop\n",
      "PRED: Jazz\n",
      "Gee, how I miss\n",
      "Your tender kiss,\n",
      "And the wonderful things we would do.\n",
      "Now I run my hands\n",
      "Through silvery strands,\n",
      "You left me blue turning gray over you.\n",
      "You used to be\n",
      "So good to me,\n",
      "That's when I \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"TRUE:\", test_df.loc[i, \"Genre\"])\n",
    "    print(\"PRED:\", id_to_genre[y_pred[i]])\n",
    "    print(test_df.loc[i, \"Lyrics\"][:200])\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db8913d9-d9cb-4c3c-937a-f19ffab21a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk 0\n",
      "Saved chunk 10\n",
      "Saved chunk 20\n",
      "Saved chunk 30\n",
      "Saved chunk 40\n",
      "Saved chunk 50\n",
      "Saved chunk 60\n",
      "Saved chunk 70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------- config ----------\n",
    "CHUNK_SIZE = 4096\n",
    "OUT_DIR = \"emb_v2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def repetition_features(text):\n",
    "    tokens = text.lower().split()\n",
    "    n = len(tokens)\n",
    "    if n == 0:\n",
    "        return np.zeros(4)\n",
    "\n",
    "    counts = Counter(tokens)\n",
    "    freqs = np.array(list(counts.values()))\n",
    "\n",
    "    uniq_ratio = len(counts) / n\n",
    "    max_freq_ratio = freqs.max() / n\n",
    "\n",
    "    lines = [l.strip() for l in text.lower().split(\"\\n\") if l.strip()]\n",
    "    if lines:\n",
    "        lc = Counter(lines)\n",
    "        repeated_line_ratio = sum(c - 1 for c in lc.values() if c > 1) / len(lines)\n",
    "    else:\n",
    "        repeated_line_ratio = 0.0\n",
    "\n",
    "    probs = freqs / n\n",
    "    entropy = -np.sum(probs * np.log(probs + 1e-12))\n",
    "    entropy /= math.log(len(freqs) + 1e-12)\n",
    "\n",
    "    return np.array([uniq_ratio, max_freq_ratio, repeated_line_ratio, entropy])\n",
    "\n",
    "    pd.read_csv(\n",
    "        \"./train.csv\",\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        usecols=[\"Lyrics\", \"Genre\"]\n",
    "    )\n",
    "):\n",
    "    texts = chunk[\"Lyrics\"].fillna(\"\").tolist()\n",
    "    texts = [t[:2000] for t in texts]  # keep consistent\n",
    "\n",
    "    word_cnt = np.array([len(t.split()) for t in texts])\n",
    "    line_cnt = np.array([t.count(\"\\n\") + 1 for t in texts])\n",
    "\n",
    "    length_feats = np.stack([\n",
    "        np.log1p(char_cnt),\n",
    "        np.log1p(word_cnt),\n",
    "        np.log1p(line_cnt)\n",
    "    ], axis=1)\n",
    "\n",
    "    rep_feats = np.vstack([repetition_features(t) for t in texts])\n",
    "\n",
    "    X_emb = model.encode(texts, batch_size=64, show_progress_bar=False)\n",
    "\n",
    "    X = np.hstack([X_emb, length_feats, rep_feats])\n",
    "\n",
    "    y = chunk[\"Genre\"].map(genre_to_id).to_numpy()\n",
    "\n",
    "    np.save(f\"{OUT_DIR}/X_{i}.npy\", X)\n",
    "    np.save(f\"{OUT_DIR}/y_{i}.npy\", y)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Saved chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b3aa393-e535-47bb-9807-8d2a1961b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Boosted rounds: 2130\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---------- XGBoost params ----------\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(genre_to_id),\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"nthread\": -1\n",
    "}\n",
    "\n",
    "booster = None\n",
    "\n",
    "files = sorted(f for f in os.listdir(\"emb_v2\") if f.startswith(\"X_\"))\n",
    "\n",
    "for f in files:\n",
    "    idx = f.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    X = np.load(f\"emb_v2/X_{idx}.npy\")\n",
    "    y = np.load(f\"emb_v2/y_{idx}.npy\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=30,\n",
    "        xgb_model=booster\n",
    "    )\n",
    "\n",
    "print(\"Training finished\")\n",
    "print(\"Boosted rounds:\", booster.num_boosted_rounds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b5f459f-c4cc-4c11-88a9-bf59b3a8da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390763298ac94544a2045b89430d8fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.23516068052930056\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def repetition_features(text):\n",
    "    tokens = text.lower().split()\n",
    "    n = len(tokens)\n",
    "    if n == 0:\n",
    "        return np.zeros(4)\n",
    "\n",
    "    counts = Counter(tokens)\n",
    "    freqs = np.array(list(counts.values()))\n",
    "\n",
    "    uniq_ratio = len(counts) / n\n",
    "    max_freq_ratio = freqs.max() / n\n",
    "\n",
    "    lines = [l.strip() for l in text.lower().split(\"\\n\") if l.strip()]\n",
    "    if lines:\n",
    "        lc = Counter(lines)\n",
    "        repeated_line_ratio = sum(c - 1 for c in lc.values() if c > 1) / len(lines)\n",
    "    else:\n",
    "        repeated_line_ratio = 0.0\n",
    "\n",
    "    probs = freqs / n\n",
    "    entropy = -np.sum(probs * np.log(probs + 1e-12))\n",
    "    entropy /= math.log(len(freqs) + 1e-12)\n",
    "\n",
    "    return np.array([uniq_ratio, max_freq_ratio, repeated_line_ratio, entropy])\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"./test.csv\",\n",
    "    usecols=[\"Lyrics\", \"Genre\"]\n",
    ")\n",
    "\n",
    "y_true = test_df[\"Genre\"].map(genre_to_id).to_numpy()\n",
    "\n",
    "texts = test_df[\"Lyrics\"].fillna(\"\").tolist()\n",
    "texts = [t[:2000] for t in texts]\n",
    "\n",
    "char_cnt = np.array([len(t) for t in texts])\n",
    "word_cnt = np.array([len(t.split()) for t in texts])\n",
    "line_cnt = np.array([t.count(\"\\n\") + 1 for t in texts])\n",
    "\n",
    "length_feats = np.stack([\n",
    "    np.log1p(char_cnt),\n",
    "    np.log1p(word_cnt),\n",
    "    np.log1p(line_cnt)\n",
    "], axis=1)\n",
    "\n",
    "rep_feats = np.vstack([repetition_features(t) for t in texts])\n",
    "\n",
    "X_emb = model.encode(\n",
    "    texts,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "X_test = np.hstack([X_emb, length_feats, rep_feats])\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "probs = booster.predict(dtest)\n",
    "y_pred = probs.argmax(axis=1)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02e84696-94b4-4d4b-9d66-7fed0bf2a8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE: Hip-Hop\n",
      "PRED: Rock\n",
      "------------------------------\n",
      "TRUE: Indie\n",
      "PRED: Pop\n",
      "------------------------------\n",
      "TRUE: Metal\n",
      "PRED: Rock\n",
      "------------------------------\n",
      "TRUE: Pop\n",
      "PRED: Pop\n",
      "------------------------------\n",
      "TRUE: Hip-Hop\n",
      "PRED: Rock\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"TRUE:\", test_df.loc[i, \"Genre\"])\n",
    "    print(\"PRED:\", id_to_genre[y_pred[i]])\n",
    "    print(\"-\"*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0e20fa4-9761-467c-9355-530c3076180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsed label map: {'Country': 0, 'Electronic': 1, 'Hip-Hop': 2, 'Jazz': 3, 'Pop': 4, 'Rock': 5}\n",
      "Using CPU for XGBoost\n",
      "Training finished. Boosted rounds: 2130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903eb077c05b446b84f21167617e79ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsed-genre accuracy: 0.09792060491493383\n",
      "\n",
      "Final labels:\n",
      "0 → Country\n",
      "1 → Electronic\n",
      "2 → Hip-Hop\n",
      "3 → Jazz\n",
      "4 → Pop\n",
      "5 → Rock\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "original_id_to_genre = {\n",
    "    0: \"Rock\",\n",
    "    1: \"Indie\",\n",
    "    2: \"Metal\",\n",
    "    3: \"Pop\",\n",
    "    4: \"R&B\",\n",
    "    5: \"Hip-Hop\",\n",
    "    6: \"Country\",\n",
    "    7: \"Folk\",\n",
    "    8: \"Jazz\",\n",
    "    9: \"Electronic\"\n",
    "}\n",
    "\n",
    "genre_map = {\n",
    "    \"Rock\": \"Rock\",\n",
    "    \"Indie\": \"Rock\",\n",
    "    \"Metal\": \"Rock\",\n",
    "    \"Pop\": \"Pop\",\n",
    "    \"R&B\": \"Pop\",\n",
    "    \"Hip-Hop\": \"Hip-Hop\",\n",
    "    \"Country\": \"Country\",\n",
    "    \"Folk\": \"Country\",\n",
    "    \"Jazz\": \"Jazz\",\n",
    "    \"Electronic\": \"Electronic\"\n",
    "}\n",
    "\n",
    "collapsed_genres = sorted(set(genre_map.values()))\n",
    "collapsed_genre_to_id = {g: i for i, g in enumerate(collapsed_genres)}\n",
    "collapsed_id_to_genre = {i: g for g, i in collapsed_genre_to_id.items()}\n",
    "\n",
    "# numeric collapse map: original_id -> collapsed_id\n",
    "collapse_id_map = {\n",
    "    oid: collapsed_genre_to_id[genre_map[gname]]\n",
    "    for oid, gname in original_id_to_genre.items()\n",
    "}\n",
    "\n",
    "print(\"Collapsed label map:\", collapsed_genre_to_id)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(collapsed_genre_to_id),\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    xgb.DeviceQuantileDMatrix\n",
    "    params[\"tree_method\"] = \"gpu_hist\"\n",
    "    params[\"predictor\"] = \"gpu_predictor\"\n",
    "    print(\"Using GPU for XGBoost\")\n",
    "except Exception:\n",
    "    params[\"tree_method\"] = \"hist\"\n",
    "    params[\"nthread\"] = -1\n",
    "    print(\"Using CPU for XGBoost\")\n",
    "\n",
    "\n",
    "booster = None\n",
    "\n",
    "X_files = sorted(f for f in os.listdir(\"emb\") if f.startswith(\"X_\"))\n",
    "\n",
    "for f in X_files:\n",
    "    idx = f.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    X = np.load(f\"emb/X_{idx}.npy\")\n",
    "    y_orig = np.load(f\"emb/y_{idx}.npy\")\n",
    "\n",
    "    # collapse labels NUMERICALLY (no CSV involved)\n",
    "    y = np.array([collapse_id_map[int(g)] for g in y_orig])\n",
    "\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=30,\n",
    "        xgb_model=booster\n",
    "    )\n",
    "\n",
    "print(\"Training finished. Boosted rounds:\", booster.num_boosted_rounds())\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"./test.csv\",\n",
    "    usecols=[\"Lyrics\", \"Genre\"]\n",
    ")\n",
    "\n",
    "y_true = np.array([\n",
    "    collapsed_genre_to_id[genre_map[g]]\n",
    "    for g in test_df[\"Genre\"]\n",
    "])\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = test_df[\"Lyrics\"].fillna(\"\").tolist()\n",
    "texts = [t[:2000] for t in texts]\n",
    "\n",
    "X_test = model.encode(\n",
    "    texts,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred = booster.predict(dtest).argmax(axis=1)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Collapsed-genre accuracy:\", acc)\n",
    "\n",
    "print(\"\\nFinal labels:\")\n",
    "for i in collapsed_id_to_genre:\n",
    "    print(i, \"→\", collapsed_id_to_genre[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd87e558-aa30-41c9-b68d-ca12da0ea2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsed genres: {'Country': 0, 'Electronic': 1, 'Hip-Hop': 2, 'Jazz': 3, 'Pop': 4, 'Rock': 5}\n",
      "Using device for embeddings: cuda\n",
      "Trained on 4,096 rows\n",
      "\n",
      "Training finished\n",
      "Total rows seen: 290183\n",
      "Boosted rounds: 355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1ee94905d1490a8d681710a8bce834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collapsed-genre accuracy: 0.44473850031505985\n",
      "\n",
      "Label mapping:\n",
      "0 → Country\n",
      "1 → Electronic\n",
      "2 → Hip-Hop\n",
      "3 → Jazz\n",
      "4 → Pop\n",
      "5 → Rock\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "TRAIN_PATH = \"./train.csv\"\n",
    "TEST_PATH  = \"./test.csv\"\n",
    "\n",
    "CHUNK_SIZE = 4096\n",
    "MAX_LEN = 2000\n",
    "EMB_BATCH = 256\n",
    "BOOST_ROUNDS_PER_CHUNK = 5\n",
    "\n",
    "genre_map = {\n",
    "    \"Rock\": \"Rock\",\n",
    "    \"Indie\": \"Rock\",\n",
    "    \"Metal\": \"Rock\",\n",
    "    \"Pop\": \"Pop\",\n",
    "    \"R&B\": \"Pop\",\n",
    "    \"Hip-Hop\": \"Hip-Hop\",\n",
    "    \"Country\": \"Country\",\n",
    "    \"Folk\": \"Country\",\n",
    "    \"Jazz\": \"Jazz\",\n",
    "    \"Electronic\": \"Electronic\"\n",
    "}\n",
    "\n",
    "collapsed_genres = sorted(set(genre_map.values()))\n",
    "genre_to_id = {g: i for i, g in enumerate(collapsed_genres)}\n",
    "id_to_genre = {i: g for g, i in genre_to_id.items()}\n",
    "\n",
    "print(\"Collapsed genres:\", genre_to_id)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device for embeddings:\", device)\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(genre_to_id),\n",
    "    \"tree_method\": \"hist\",   \n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"nthread\": -1\n",
    "}\n",
    "\n",
    "booster = None\n",
    "total_rows = 0\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    TRAIN_PATH,\n",
    "    chunksize=CHUNK_SIZE,\n",
    "    usecols=[\"Lyrics\", \"Genre\"]\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    chunk = chunk.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    texts = chunk[\"Lyrics\"].fillna(\"\").astype(str).str.slice(0, MAX_LEN).tolist()\n",
    "    y = np.array([genre_to_id[genre_map[g]] for g in chunk[\"Genre\"]])\n",
    "\n",
    "    if len(texts) == 0:\n",
    "        continue\n",
    "\n",
    "    X = model.encode(\n",
    "        texts,\n",
    "        batch_size=EMB_BATCH,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=BOOST_ROUNDS_PER_CHUNK,\n",
    "        xgb_model=booster\n",
    "    )\n",
    "\n",
    "    total_rows += len(texts)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Trained on {total_rows:,} rows\")\n",
    "\n",
    "print(\"\\nTraining finished\")\n",
    "print(\"Total rows seen:\", total_rows)\n",
    "print(\"Boosted rounds:\", booster.num_boosted_rounds())\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    TEST_PATH,\n",
    "    usecols=[\"Lyrics\", \"Genre\"]\n",
    ")\n",
    "\n",
    "test_texts = test_df[\"Lyrics\"].fillna(\"\").astype(str).str.slice(0, MAX_LEN).tolist()\n",
    "y_test = np.array([genre_to_id[genre_map[g]] for g in test_df[\"Genre\"]])\n",
    "\n",
    "X_test = model.encode(\n",
    "    test_texts,\n",
    "    batch_size=EMB_BATCH,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred = booster.predict(dtest).argmax(axis=1)\n",
    "\n",
    "acc = (y_pred == y_test).mean()\n",
    "\n",
    "print(\"\\nCollapsed-genre accuracy:\", acc)\n",
    "print(\"\\nLabel mapping:\")\n",
    "for i in id_to_genre:\n",
    "    print(i, \"→\", id_to_genre[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89aeae1-99eb-4701-994b-aae9ea975f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-22.0.0-cp314-cp314-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Using cached pyarrow-22.0.0-cp314-cp314-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6ad2204-c5f3-4b8e-8aa5-8f7b7137576e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "model.save(\"models/st_transformer_model\")\n",
    "\n",
    "booster.save_model(\"models/genre_classifier.ubj\")\n",
    "\n",
    "metadata = {\n",
    "    \"genre_to_id\": genre_to_id,\n",
    "    \"id_to_genre\": {int(k): v for k, v in id_to_genre.items()},\n",
    "    \"genre_map\": genre_map\n",
    "}\n",
    "with open(\"models/metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "np.save(\"models/test_embeddings.npy\", X_test)\n",
    "\n",
    "test_df_clean = test_df.reset_index(drop=True)\n",
    "cols_to_save = ['Lyrics', 'Genre'] \n",
    "for col in cols_to_save:\n",
    "    if col in test_df_clean.columns:\n",
    "        test_df_clean[col] = test_df_clean[col].astype(str)\n",
    "\n",
    "test_df_clean[cols_to_save].to_feather(\"models/test_metadata.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee6265-8445-46db-88d1-e538121de09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
